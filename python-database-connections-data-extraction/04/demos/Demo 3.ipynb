{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5895b66-fbdc-44da-b312-382a1d2210c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL successfully!\n",
      "Employees table dropped and recreated successfully.\n",
      "Inserted 20 sample employee records successfully.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Step 1: Establish Connection to MySQL\n",
    "db_url = \"mysql+pymysql://root:mysql@localhost/sakila\"  # Update with actual credentials\n",
    "engine = create_engine(db_url)\n",
    "print(\"Connected to MySQL successfully!\")\n",
    "\n",
    "# Step 2: Drop and Recreate Employees Table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS employees;\"))\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE employees (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            name VARCHAR(100),\n",
    "            department VARCHAR(50),\n",
    "            salary DECIMAL(10,2),\n",
    "            hire_date DATE\n",
    "        );\n",
    "    \"\"\"))\n",
    "    print(\"Employees table dropped and recreated successfully.\")\n",
    "    \n",
    "    # Insert 20 sample rows\n",
    "    employees_data = [\n",
    "        {\"name\": f\"Employee{i}\", \"department\": \"Department\" + str(i % 5), \"salary\": 50000 + (i * 1000), \"hire_date\": f\"202{(i%3)+1}-0{(i%9)+1}-15\"}\n",
    "        for i in range(1, 21)\n",
    "    ]\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO employees (name, department, salary, hire_date) VALUES \n",
    "        (:name, :department, :salary, :hire_date);\n",
    "    \"\"\"), employees_data)\n",
    "    conn.commit()\n",
    "    print(\"Inserted 20 sample employee records successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc07b9f-e3ae-422f-9beb-62ad5962d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data in batches using OFFSET:\n",
      "\n",
      "Batch 1:\n",
      "   id       name   department    salary   hire_date\n",
      "0   1  Employee1  Department1  51000.00  2022-02-15\n",
      "1   2  Employee2  Department2  52000.00  2023-03-15\n",
      "2   3  Employee3  Department3  53000.00  2021-04-15\n",
      "3   4  Employee4  Department4  54000.00  2022-05-15\n",
      "4   5  Employee5  Department0  55000.00  2023-06-15\n",
      "\n",
      "Batch 2:\n",
      "   id        name   department    salary   hire_date\n",
      "0   6   Employee6  Department1  56000.00  2021-07-15\n",
      "1   7   Employee7  Department2  57000.00  2022-08-15\n",
      "2   8   Employee8  Department3  58000.00  2023-09-15\n",
      "3   9   Employee9  Department4  59000.00  2021-01-15\n",
      "4  10  Employee10  Department0  60000.00  2022-02-15\n",
      "\n",
      "Batch 3:\n",
      "   id        name   department    salary   hire_date\n",
      "0  11  Employee11  Department1  61000.00  2023-03-15\n",
      "1  12  Employee12  Department2  62000.00  2021-04-15\n",
      "2  13  Employee13  Department3  63000.00  2022-05-15\n",
      "3  14  Employee14  Department4  64000.00  2023-06-15\n",
      "4  15  Employee15  Department0  65000.00  2021-07-15\n",
      "\n",
      "Batch 4:\n",
      "   id        name   department    salary   hire_date\n",
      "0  16  Employee16  Department1  66000.00  2022-08-15\n",
      "1  17  Employee17  Department2  67000.00  2023-09-15\n",
      "2  18  Employee18  Department3  68000.00  2021-01-15\n",
      "3  19  Employee19  Department4  69000.00  2022-02-15\n",
      "4  20  Employee20  Department0  70000.00  2023-03-15\n",
      "\n",
      "All data retrieved using batch processing.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define Function for Pagination Using LIMIT/OFFSET\n",
    "def fetch_data_with_pagination(limit, offset):\n",
    "    query = text(\"SELECT * FROM employees LIMIT :limit OFFSET :offset;\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\"limit\": limit, \"offset\": offset})\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    return df\n",
    "\n",
    "# Step 4: Fetch Large Dataset in Chunks (Batch Processing)\n",
    "chunk_size = 5  # Adjust chunk size as needed\n",
    "offset = 0\n",
    "print(\"Fetching data in batches using OFFSET:\")\n",
    "while True:\n",
    "    df_chunk = fetch_data_with_pagination(chunk_size, offset)\n",
    "    if df_chunk.empty:\n",
    "        break\n",
    "    print(f\"\\nBatch {offset // chunk_size + 1}:\")\n",
    "    print(df_chunk)\n",
    "    offset += chunk_size\n",
    "\n",
    "print(\"\\nAll data retrieved using batch processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306a1eb-a7e5-4d39-b55b-adf7e8348da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
